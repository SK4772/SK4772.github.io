<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>2010-Domain Adaptation via Transfer Component Analysis（TCA）</title>
    <url>/2024/12/16/2010-Domain-Adaptation-via-Transfer-Component-Analysis%EF%BC%88TCA%EF%BC%89/</url>
    <content><![CDATA[<h3
id="domain-adaptation-via-transfer-component-analysistca">2010-Domain
Adaptation via Transfer Component Analysis（TCA）</h3>
<h6 id="论文背景">论文背景:</h6>
<p>​ Domain adaptation(域自适应)
通过训练与目标与<strong>相关但不相同</strong>的源域数据来实现目标域上的任务。</p>
<h6 id="动机">动机：</h6>
<p>​ MMD（Maximum mean discrepancy ）旨在学习一个映射函数<span
class="math inline">\(\phi\)</span>去减少域之间的分布差异: <span
class="math display">\[
\mathrm{Dist}(\mathrm{X,Y})=\left\|\frac1{n_1}\sum_{i=1}^{n_1}\phi(x_i)-\frac1{n_2}\sum_{i=1}^{n_2}\phi(y_i)\right\|_{\mathcal{H}}.
\]</span> 通过将两个样本映射到再现核希尔伯特空间RKHS（Reproducing Kernel
Hilbert
Space），并取映射后样本均值的距离衡量两个样本分布的差异。<strong>然而，
<span class="math inline">\(\phi\)</span>通常是高度非线性的，直接优化
可能会陷入较差的局部最小值（不理解）</strong>。因此MMDE(Maximum Mean
Discrepancy Embedding)被提出使用核学习衡量分布差异： <span
class="math display">\[
\mathrm{Dist}(X_S^{\prime},X_T^{\prime})=\mathrm{tr}(KL)
\]</span> 其中，<span
class="math inline">\(K=\begin{bmatrix}K_{S,S}&amp;K_{S,T}\\K_{T,S}&amp;K_{T,T}\end{bmatrix}\)</span>表示学习到的核矩阵<span
class="math inline">\(K\)</span>，用于衡量域内样本的相似度，以及域间样本的相似度。并且<span
class="math inline">\(L=[L_{ij}]\succeq0\mathrm{~with~}L_{ij}=\frac1{n_1^2}\text{
if }x_i,x_j\in X_S;\:L_{ij}=\frac1{n_2^2}\mathrm{if~}x_i,x_j\in
X_T\text{; otherwise, }-\frac1{n_1n_2}.\)</span>
优化此问题需要解决半正定优化问题SDP，这<strong>代价是昂贵</strong>的；并且为了找到相同的低维表示，获得的
K 必须进一步通过 PCA 进行后处理。这可能会<strong>丢弃 K
中的有用信息</strong>；并且此种学习是转导式，<strong>缺乏泛化能力</strong>
b) <strong>计算开销大</strong></p>
<h6 id="方法内容">方法内容：</h6>
<p>​ 假设前提: <span class="math inline">\(P \neq
Q\)</span>，但是通过映射函数<span
class="math inline">\(\phi\)</span>可以达到<span
class="math inline">\(P(Y_S|\phi(X_S))=P(Y_T|\phi(X_T))\)</span>。TCA
使用<strong>最大平均差异</strong> (MMD)
来学习<strong>再生内核希尔伯特空间</strong> (RKHS)
中的一些跨域传输分量（<strong>transfer
component</strong>），也是寻找一个子空间中使不同域中的数据分布彼此接近。首先它使用了矩阵分解用于核矩阵<span
class="math inline">\(K=(KK^{-1/2})(K^{-1/2}K)\)</span>然.后引入一个<span
class="math inline">\((n_1+n_2)\times m\)</span>大小的矩阵W,其中<span
class="math inline">\(m\ll n_1+n_2\)</span>： <span
class="math display">\[
\widetilde{K}=(KK^{-1/2}\widetilde{W})(\widetilde{W}^\top
K^{-1/2}K)=KWW^\top K,
\]</span> 其中<span
class="math inline">\(W=K^{-1/2}\widetilde{W}\in\mathbb{R}^{(n_1+n_2)\times
m}\)</span> ,两个样本之间的分布差异由下式给出： <span
class="math display">\[
\widetilde{k}(x_i,x_j)=k_{x_i}^\top WW^\top k_{x_j},
\]</span> 其中<span
class="math inline">\(\begin{array}{rcl}k_x&amp;=&amp;[k(x_1,x),\ldots,k(x_{n_1+n_2},x)]^\top\end{array}\)</span>，这样的话不仅衡量了源域和目标域之之间的差异，还衡量了源域与源域的其余样本差异，有助于提出泛化能力。用新的K替代原先的K,得到
<span class="math display">\[
\begin{aligned}\mathrm{Dist}(X_S^{\prime},X_T^{\prime})&amp;=\mathrm{tr}((KWW^\top
K)L)\\&amp;=\mathrm{tr}(W^\top KLKW).\end{aligned}
\]</span> 最终目标函数为： <span class="math display">\[
\begin{aligned}\min_W&amp;\operatorname{tr}(W^\top
W)+\mu\operatorname{tr}(W^\top KLKW)\\\text{s.t.}&amp;W^\top
KHKW=I,\end{aligned}
\]</span>
其中第一项用于控制W的复杂度，可以避免广义特征分解中分母的秩不足，而约束项则是防止平凡解。</p>
<h6 id="优化">优化</h6>
<p><span class="math display">\[
W=(I+\mu KLK)^{-1}KHKWZ.
\]</span></p>
]]></content>
      <categories>
        <category>论文阅读</category>
      </categories>
      <tags>
        <tag>域自适应</tag>
        <tag>MMD</tag>
      </tags>
  </entry>
  <entry>
    <title>2013-Transfer Feature Learning with Joint Distribution Adaptation（JDA）</title>
    <url>/2024/12/17/2013-Transfer-Feature-Learning-with-Joint-Distribution-Adaptation/</url>
    <content><![CDATA[<h2 id="论文阅读">论文阅读</h2>
<h3
id="transfer-feature-learning-with-joint-distribution-adaptationjda">2013-Transfer
Feature Learning with Joint Distribution Adaptation（JDA）</h3>
<h4 id="论文背景">论文背景:</h4>
<p>​
计算机视觉中，迁移学习被提出用作<strong>利用源域中丰富的标记数据为目标域构建准确的分类器</strong>。</p>
<h4 id="动机">动机：</h4>
<p><img src="https://gitee.com/sk4772/photo/raw/master/photo/20241217141255803.png" alt="image-20241217141248646" style="zoom: 80%;" /></p>
<p>​
在进行源域与目标域仅考虑对两域的<strong>边缘分布</strong>对齐，而没有对齐<strong>条件分布</strong>。如上图所示，两域的边缘分布与条件分布大概率是都不行同的，因此仅考虑边缘分布是不够的。</p>
<h4 id="方法提出">方法提出：</h4>
<p>​
在跨域问题中，源域与目标域的采样不同导致两者的分布差异。迁移学习/域自适应主要的计算问题就是如何减少两者的差异。分布差异主要包括了两方面，即：<strong>边缘分布与条件分布</strong>。现有的大多数方法是基于边</p>
<p>际分布或条件分布来衡量分布差异，这样<strong>仅考虑一方面</strong>是不够充分的。论文提出了一种新颖的迁移学习解决方案，称为联合分布适应（
Joint Distribution
Adaptation，JDA），在保留数据主要信息的<strong>降维</strong>过程中<strong>联合适应边缘分布和条件分布</strong>。具体来说，使用了非参数最大平均差异（MMD）来测量边际分布和条件分布的差异（<strong>这里说的非参数也就是说不需要对数据分布做假设</strong>），并将其与主成分分析（PCA）集成以构建有效且<strong>鲁棒</strong>的特征表示。</p>
<p>​ 接下来，具体介绍
JDA算法。源域和目标域分布差异大致可以被认为是边缘分布差异以及联合分布差异的总和，即
<span class="math display">\[
\begin{aligned}&amp;\min_{T}\left\|\mathbb{E}_{P(\mathbf{x}_s,y_s)}\left[T\left(\mathbf{x}_s\right),y_s\right]-\mathbb{E}_{P(\mathbf{x}_t,y_t)}\left[T\left(\mathbf{x}_t\right),y_t\right]\right\|^2\\&amp;\approx\left\|\mathbb{E}_{P_s(\mathbf{x}_s)}\left[T\left(\mathbf{x}_s\right)\right]-\mathbb{E}_{P_t(\mathbf{x}_t)}\left[T\left(\mathbf{x}_t\right)\right]\right\|^2\\&amp;+\left\|\mathbb{E}_{Q_s(y_s|\mathbf{x}_s)}\left[y_s|T\left(\mathbf{x}_s\right)\right]-\mathbb{E}_{Q_t(y_t|\mathbf{x}_t)}\left[y_t|T\left(\mathbf{x}_t\right)\right]\right\|^2\end{aligned}
\]</span> <strong>度量边缘分布：</strong>使用基础的MMD即可 <span
class="math display">\[
\left\|\frac1{n_\text{s}}\sum_{i=1}^{n_s}\mathrm{A}^\mathrm{T}\mathrm{x}_i-\frac1{n_t}\sum_{j=n_s+1}^{n_s+n_t}\mathrm{A}^\mathrm{T}\mathrm{x}_j\right\|^2=\mathrm{tr}\left(\mathrm{A}^\mathrm{T}\mathbf{X}\mathrm{M}_0\mathbf{X}^\mathrm{T}\mathrm{A}\right)
\]</span>
<strong>条件分布度量：</strong>这个就比较困难，因为目标域是只有样本特征<span
class="math inline">\(X_t\)</span>，而缺乏对应的标签。因此论文提出可以使用伪标签（<strong>pseudo
label</strong>）进行评估 <span class="math display">\[
\left\|\frac{1}{n_{s}^{(c)}}\sum_{\mathbf{x}_{i}\in\mathcal{D}_{s}^{(c)}}\mathrm{A}^{\mathrm{T}}\mathbf{x}_{i}-\frac{1}{n_{t}^{(c)}}\sum_{\mathbf{x}_{j}\in\mathcal{D}_{t}^{(c)}}\mathrm{A}^{\mathrm{T}}\mathbf{x}_{j}\right\|^{2}=\mathrm{tr}\left(\mathrm{A}^{\mathrm{T}}\mathbf{X}\mathrm{M}_{c}\mathbf{X}^{\mathrm{T}}\mathbf{A}\right)
\]</span>
尽管由于边缘分布和条件分布的差异，许多伪目标标签是不正确的，但仍然可以利用它们将条件分布相匹配。<strong>理由是论文是通过探索足够的统计数据而不是密度估计来匹配分布。</strong>这样，就可以利用源分类器来改进目标分类器。</p>
<p><strong>PCA降维:</strong> <span class="math display">\[
\max_{\mathbf{A}^\mathrm{T}\mathbf{A}=\mathbf{I}}\operatorname{tr}\left(\mathbf{A}^\mathrm{T}\mathbf{X}\mathbf{H}\mathbf{X}^\mathrm{T}\mathbf{A}\right)
\]</span> ​ 结合PCA, 边缘MMD以及条件MMD,JDA的目标函数可记作 <span
class="math display">\[
\min_{\mathbf{A}^\mathrm{T}\mathbf{X}\mathbf{H}\mathbf{X}^\mathrm{T}\mathbf{A}=\mathbf{I}}\sum_{c=0}^C\mathrm{tr}\left(\mathbf{A}^\mathrm{T}\mathbf{X}\mathrm{M}_c\mathrm{X}^\mathrm{T}\mathbf{A}\right)+\lambda\left\|\mathbf{A}\right\|_F^2
\]</span> 对应拉格朗日函数<span
class="math inline">\(L=\mathrm{tr}\left(\mathbf{A}^\mathrm{T}\left(\mathbf{X}\sum_{c=0}^C\mathrm{M}_c\mathrm{X}^\mathrm{T}+\lambda\mathrm{I}\right)\mathbf{A}\right)+\mathrm{tr}\left(\left(\mathbf{I}-\mathbf{A}^\mathrm{T}\mathbf{X}\mathrm{H}\mathrm{X}^\mathrm{T}\mathrm{A}\right)\Phi\right)\)</span></p>
<p>优化：$(_{c=0}^C_c<sup>+)=</sup>$</p>
]]></content>
      <categories>
        <category>论文阅读</category>
      </categories>
      <tags>
        <tag>域自适应</tag>
        <tag>MMD</tag>
        <tag>条件分布</tag>
      </tags>
  </entry>
  <entry>
    <title>科研常用网站及软件—Csk</title>
    <url>/2024/09/01/%E7%A7%91%E7%A0%94%E5%B8%B8%E7%94%A8%E7%BD%91%E7%AB%99%E5%8F%8A%E8%BD%AF%E4%BB%B6%E2%80%94Csk/</url>
    <content><![CDATA[<h1 id="常用网站及软件csk">常用网站及软件—Csk</h1>
<p>latex安装；Winedt: Latex代码编辑器</p>
<p>JabRef: 参考文献管理</p>
<p>MATLAB: 代码（实验，绘图）</p>
<p>绘图：PPT，MATLAB，Python</p>
<p>文献阅读管理：Zotero, 知云等</p>
<p>文献网站：谷歌学术，百度学术，<a
href="https://www.scidown.cn/">Scidown</a>(文献下载)，<a
href="aminer.cn">AMiner</a>，<a
href="sci-hub.se">Sci-hub</a>（文献下载），<a
href="http://spis.hnlat.com/">SPIS</a>，<a
href="https://www.ablesci.com/">科研通</a></p>
<p>代码查找：Github, <a
href="https://paperswithcode.com">Paperwithcode</a></p>
<p>大模型：ChatGPT，kimi</p>
]]></content>
      <categories>
        <category>论文写作</category>
      </categories>
      <tags>
        <tag>基础</tag>
      </tags>
  </entry>
  <entry>
    <title>论文写作注意事项—Csk</title>
    <url>/2024/09/01/%E8%AE%BA%E6%96%87%E5%86%99%E4%BD%9C%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9%E2%80%94Csk/</url>
    <content><![CDATA[<div class="hbe hbe-container" id="hexo-blog-encrypt" data-wpm="Oh, this is an invalid password. Check and try again, please." data-whm="OOPS, these decrypted content may changed, but you can still have a look.">
  <script id="hbeData" type="hbeData" data-hmacdigest="890429309692362ac37fc249b7811b7f20212dd136f11f28d45d8dcd18c8b52c">802cd80b63fccd52ebcbbd93e4cfc45fc6fa5042d706317aa187d9196af62f5b9d448a348f3ed78c32224c27ed1c63b3533fd59f7055269f2ecf4385bf170906412f3f2a4210853562ea35d5f6506ec8508f683b8b0a54a7c4246fdd268f2c0457319c073f93d63633e0da120053c447a8bdb2a11fe29f696afaf6a1ec155a68708b91752303d903e94458edc5a27983af5ff93bc6ec91782a8e9f51cffbb6bfd476991fb69f887fb73ad2392f53f7961fa5780844965e83bc0503ced45fec5c6925a3dc3bdf06d14f910fa5d3a7b47173c59d6685646442fa37f4b0cf01afeb72bd764207db055f71db271e745966a1ede29fa50dfb67278738dfdcc2930f52bf12d84f220c9b62c6f3752124014f71d3ad9795651ca3410ff1c0983dd3663d03de33e98e441a7a5673f7c0eeceb061ff73a579974cd194985d6db7f1d149e657f29fd501b4631952333da654f4391c69b7c77ba109d6c8dd0770c69f50d170f394824c7c553767454affb8361a5e545af27f40b00d6debe0ff4a4de903ae10fc7d8bdcb15fe56b5f4a8fd809e77323143fdf5268507a0c2940edae3afe387cb6411582c3c61694493a461b9adf418168a37e2a953954376270d7c03c226c62b4e56ac4e9502b0e06d5f445f1a71db00bb1216c1de372fd4f5af2aa8264419731c95bd56c02cbed8e528a6dfa18b7d872b67cd3ee2d02a5c3a08ff11caacad479ca18ec52bf2278969e9ec55c8d6b421047df3a835cd353a70b101dfe09670d1083cba11bf03dea71541ff2868ab329f9c8d1e75a12e406de40c338954e9323131ecada3cbcdb08f7d45f0cef499cef0961767508f5b10956c0984d71ca1465b00483546034f651a189231e4615df450aca5f7c7223dd4263b9d4abbb6a54e07c605c68d90ca6c850a358ce54975ecf103e5398dcc7f8236dc76a827c343089ac2c848635179b3f1e0a2bf03fff6b2036854397ae4ad569ad8f6382eea2e0f01216c547b4a3de5b3909df826469f87f6fdd85b819a1410df1a98d29b070cdffaf10a0947aa17c192dad3638d36ff9f00ae17b34d5b23798b3357f7245e146c409e619c73d788265d5c62ba8eb0d9f995c43e0035f0c5cb5ce5fbd72865ab1660191d8bdd518750025fc77450a10327a5e5dbba8ed00e6b0bcaeb9781789fc7ed2644a89d8660a1886f41c0b9f392c28396222757ef4921f1a0fc8ef332cd5d72646da35339147ab7ceb7a5c4477ec18748951a076d564b01972dbde7396393b2bfbd5b05b96f9ffed3182108f52a53489ad0e8b27ba16e55b5389ee3eae202b94916c8c56277849d11a2951fefae9a694e6d477595b10e352ad6b21c931ce4aa2a1c530c4d78a866c428cf99e8ad607a0f5d4c57d47e4dc1c301af840212fa87a6a304ab8088ba09653db5c9c4c5cf1c22e73c4b5ba10479505aff05033f6e5b154e457c4ab885d0f591fd34a853aa3ceaaaf5130e3c7bccab9e52df6747973271ee19f3860b830a40e3bd92edcecfe95790ddd7a9878cb39815033bc8b1be6054ce3354c09b702dec679c5f72f1a7f81b3e20afba2a3d6c18fab2fc124834dd306a8a569704568a15ae12a03b3ccadcbc6234f8daefa363f1cf05f3e47ad94127616ecbfc2428fdeefce05cfeabb8ec590900a113c97e1251613d9f711ad5fad1fd315e8390d6e9eb352bbea61316d257d8a6f03ed7417c47fc0ea409d4eaba50b6454016075a5b073ec8dce3675cb71db656ae45adc6f576f80bb9ce813245f00905f53032627305854a6eaf020797e3a851f0437b364a63471bdb693e34ee3dc81899caff36019114ce291b7a9d85cdc1c4169a16db5ec80994b6f9a6197efe3d8c9cf575bfe26946182649ca0cc8f5aa2da95b36238a6624933bf82369b30b35c1d400328a9a1e33d75f6bc8b52e109e884d1a174d2260281f147a703fa4fb9db9509973d990c2980f4f1efc3739d4e0da97f0d35b17da6adc38ee4b3aecb62aeec6e4a681af2a00dcc6115a13d14b73338087783b503c293704a37ca638bc1fa89dd1e14911d071b8d52223a7b826434d8ad208193620073191d26c45c97c9c029450e2293a9b3d9af89a74bd7c80dde58392b56803179139b13ec8ebba55721939b7851fbb288e652f84c19afdae51e02e936468fabb6d485a076de3e869a711f1c6ef75bf1ac70af9b7cf3b4c460fddd07567bbe32b211544e358f35a222fa169491198faecf6295fd95392e30d5e002e350c9de7f4212f997ac341db1ce1ef644565d4f36056dd54e571e9dc2e808f5f44508e1ca0c991aca7ceabab5051a0f9c62e10fb9d57fc563c98022f832c1bee32252516cb8aef627719abb6f43631bc728c64430d7e932141fcb6150cde007fd87aa543884a2462cf4e85460eadc295431e30caa6deefa6d294b0f6146104458a37fe57e2c2820318cd48eb4118fbfe186376a6d3b99f507e424a6fa3d14b3122629d841027f9682e98822af93b6ff4927d6811b5cf94be2d0b9376b90b06b7a5befaaaf529f2b4240cc5bf265702aeac9199eef4192e0e793c9e3</script>
  <div class="hbe hbe-content">
    <div class="hbe hbe-input hbe-input-default">
      <input class="hbe hbe-input-field hbe-input-field-default" type="password" id="hbePass">
      <label class="hbe hbe-input-label hbe-input-label-default" for="hbePass">
        <span class="hbe hbe-input-label-content hbe-input-label-content-default">Hey, password is required here.</span>
      </label>
    </div>
  </div>
</div>
<script data-pjax src="/lib/hbe.js"></script><link href="/css/hbe.style.css" rel="stylesheet" type="text/css">]]></content>
      <categories>
        <category>论文写作</category>
      </categories>
      <tags>
        <tag>基础</tag>
      </tags>
  </entry>
  <entry>
    <title>迁移学习综述</title>
    <url>/2024/09/01/%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E7%BB%BC%E8%BF%B0/</url>
    <content><![CDATA[<h1 id="迁移学习">迁移学习</h1>
<h3 id="前置知识">前置知识：</h3>
<h4 id="边缘概率分布和条件概率分布">1.边缘概率分布和条件概率分布</h4>
<p>​
在迁移学习中，边缘概率分布和条件概率分布是两个重要的概念。<strong>边缘概率分布</strong>（Marginal
Probability
Distribution），即P(X)，在迁移学习中是指的是数据的特征分布。P(x)不同是说数据的产生机制不一样，比如不同角度、光照或背景的图像，不同被试者产生的生理数据、行为数据，它们都服从不同的特征分布，即边缘概率分布不一致。在迁移学习中，只要源域和目标域数据服从不同的分布规律，我们就认为二者存在边缘概率分布差异，这种差异被称为分布偏移或领域漂移（domain
shift）。<strong>条件概率分布</strong>（Conditional Probability
Distribution），即P(y|x)，在迁移学习中是指给定特征的条件下，标签的分布。在理想情况下，源域和目标域的条件概率分布是相同的。然而，在现实中并不总是成立。比如，不同被试者的生理数据通常不一样；而且即使是相同被试者，在不同状态或者时间下，进行相同的动作，生理数据也存在差异。另外，在迁移学习中，理解边缘概率分布和条件概率分布的差异是非常重要的，因为这可以帮助我们选择合适的迁移学习策略。例如，如果源域和目标域在边缘概率分布上有较大差异，但在条件概率分布上差异较小，那么我们可能会选择使用特征选择或者特征转换的方法来进行迁移学习。反之，如果源域和目标域在条件概率分布上有较大差异，那么我们可能需要使用更复杂的迁移学习方法，例如重新标注一些目标域的数据，或者使用对抗性训练等方法来解决这个问题。</p>
<p>​ 我们通常解决的是边缘概率分布以及条件概率分布的不同情况即<span
class="math inline">\(P_s(X)\neq P_t(X)\)</span>且<span
class="math inline">\(P_s(Y|X)\neq
P_t(Y|X)\)</span>。源域和目标域的数据分布存在差异即<span
class="math inline">\(P_s(X,Y)\neq
P_t(X,Y)\)</span>，通过贝叶斯公式，可以将这个联合概率分解为：<span
class="math inline">\(P(X,Y)= P(Y|X)P(X)\)</span>
因此可以将源域和目标域数据分布不同转化为边缘概率分布和条件概率分布。</p>
<h4 id="mmd">2.MMD</h4>
<p>​
既然存在着分布上的差异，那么在迁移学习中便要尽可能减少分布之间的差异。其中所必须思考的问题是如何度量这种差异，只有度量出差异后，才能尽可能减少分布上的差异。</p>
<p>首先，我们考虑如何描述一个随机变量，最直接的方法就是给出它的概率分布函数
f(x)
。一些简单的分布可以这么干，比如正态分布给出均值和方差就可以确定，但是对于一些<strong>复杂的、高维的随机变量</strong>，我们无法给出它们的分布函数。这时候我们可以用随机变量的矩来描述一个随机变量，比如一阶中心矩是均值，二阶中心矩是方差等等。如果两个分布的均值和方差都相同的话，它们应该很相似，比如同样均值和方差的高斯分布和拉普拉斯分布。但是很明显，均值和方差并不能完全代表一个分布，这时候我们就需<strong>要更高阶的矩</strong>来描述一个分布[<a
href="https://zhuanlan.zhihu.com/p/163839117#ref_1">1]</a>。举个例子，就好比描述人一样，如果两个人身高、轮廓都一样，我们会说这两个人很像。但是如果要说这两个人是一个人的话，我们如要更多的信息，比如血型、DNA等更加复杂的信息。</p>
<p>而MMD的基本思想就是，如果两个随机变量的任意阶都相同的话，那么两个分布就是一致的。而当两个分布不相同的话，那么使得<strong>两个分布之间差距最大的那个矩</strong>应该被用来作为度量两个分布的标准。
<span class="math display">\[
\begin{equation*}
    \begin{split}
        &amp;\left\|\frac{1}{n_{s}} \sum_{i=1}^{n_{s}}
\mathbf{A}^{\mathrm{T}} \mathbf{x}_{i}-\frac{1}{n_{t}}
\sum_{j=n_{s}+1}^{n_{s}+n_{t}} \mathbf{A}^{\mathrm{T}}
\mathbf{x}_{j}\right\|^{2}\\
        &amp;=\left\|\frac{1}{n_{s}} \mathbf{A}^{\mathrm{T}}
\begin{bmatrix}
\mathbf{x}_1 &amp; \mathbf{x}_2 &amp; \cdots &amp; \mathbf{x}_{n_s}
\end{bmatrix}_{1 \times n_s} \begin{bmatrix}
1\\
1\\
\vdots\\
1
\end{bmatrix}_{n_s \times 1} -\frac{1}{n_{t}} \mathbf{A}^{\mathrm{T}}
\begin{bmatrix}
\mathbf{x}_1 &amp; \mathbf{x}_2 &amp; \cdots &amp; \mathbf{x}_{n_t}
\end{bmatrix}_{1 \times n_t} \begin{bmatrix}
1\\
1\\
\vdots\\
1
\end{bmatrix}_{n_t \times 1}\right\|^{2}\\
&amp;=\operatorname{tr} \left(\frac{1}{n^2_{s}} \mathbf{A}^{\mathrm{T}}
\mathbf{X}_s \mathbf{1} (\mathbf{A}^{\mathrm{T}} \mathbf{X}_s
\mathbf{1})^{\mathrm{T}} +\frac{1}{n^2_{t}} \mathbf{A}^{\mathrm{T}}
\mathbf{X}_t \mathbf{1} (\mathbf{A}^{\mathrm{T}} \mathbf{X}_t
\mathbf{1})^{\mathrm{T}} - \frac{1}{n_s n_t} \mathbf{A}^{\mathrm{T}}
\mathbf{X}_s \mathbf{1} (\mathbf{A}^{\mathrm{T}} \mathbf{X}_t
\mathbf{1})^{\mathrm{T}} - \frac{1}{n_s n_t} \mathbf{A}^{\mathrm{T}}
\mathbf{X}_t \mathbf{1} (\mathbf{A}^{\mathrm{T}} \mathbf{X}_s
\mathbf{1})^{\mathrm{T}}\right)\\
&amp;=\operatorname{tr} \left(\frac{1}{n^2_{s}} \mathbf{A}^{\mathrm{T}}
\mathbf{X}_s \mathbf{1} \mathbf{1}^{\mathrm{T}}
\mathbf{X}_s^{\mathrm{T}} \mathbf{A} +\frac{1}{n^2_{t}}
\mathbf{A}^{\mathrm{T}} \mathbf{X}_t \mathbf{1} \mathbf{1}^{\mathrm{T}}
\mathbf{X}_t^{\mathrm{T}} \mathbf{A} - \frac{1}{n_s n_t}
\mathbf{A}^{\mathrm{T}} \mathbf{X}_s \mathbf{1} \mathbf{1}^{\mathrm{T}}
\mathbf{X}_t^{\mathrm{T}} - \frac{1}{n_s n_t} \mathbf{A}^{\mathrm{T}}
\mathbf{X}_t \mathbf{1} \mathbf{1}^{\mathrm{T}}
\mathbf{X}_s^{\mathrm{T}} \right)\\
&amp;=\operatorname{tr} \left[ \mathbf{A}^{\mathrm{T}} \left(
\frac{1}{n^2_s} \mathbf{1}\mathbf{1}^{\mathrm{T}}
\mathbf{X}_s^{\mathrm{T}} \mathbf{X}_s + \frac{1}{n^2_t}
\mathbf{1}\mathbf{1}^{\mathrm{T}} \mathbf{X}_t^{\mathrm{T}} \mathbf{X}_t
- \frac{1}{n_s n_t} \mathbf{1} \mathbf{1}^{\mathrm{T}}
\mathbf{X}_s^{\mathrm{T}} \mathbf{X}_t - \frac{1}{n_s n_t} \mathbf{1}
\mathbf{1}^{\mathrm{T}} \mathbf{X}_t^{\mathrm{T}} \mathbf{X}_s \right)
\mathbf{A} \right]\\
&amp;=\operatorname{tr} \left( \mathbf{A}^{\mathrm{T}} \begin{bmatrix}
\mathbf{X}_s &amp; \mathbf{X}_t
\end{bmatrix} \begin{bmatrix}
\frac{1}{n^2_s} \mathbf{1}\mathbf{1}^{\mathrm{T}} &amp; \frac{-1}{n_s
n_t} \mathbf{1}\mathbf{1}^{\mathrm{T}} \\
\frac{-1}{n_s n_t} \mathbf{1}\mathbf{1}^{\mathrm{T}} &amp;
\frac{1}{n^2_t} \mathbf{1}\mathbf{1}^{\mathrm{T}}
\end{bmatrix}  \begin{bmatrix}
\mathbf{X}_s \\ \mathbf{X}_t
\end{bmatrix} \mathbf{A} \right)\\
&amp;=\operatorname{tr} \left( \mathbf{A}^{\mathrm{T}} \mathbf{X}
\mathbf{M} \mathbf{X}^{\mathrm{T}}  \mathbf{A} \right)
    \end{split}
\end{equation*}
\]</span></p>
<h4 id="global-distance-and-local-distance">3.Global distance and Local
distance:</h4>
<h4 id="判别信息">4.判别信息</h4>
<h4 id="交叉熵损失.">5交叉熵损失.</h4>
<p>​
假设我们有一个三类分类问题（例如，猫、狗和兔子），我们的模型需要对一张图片进行分类。我们设定真实的标签（one-hot
编码）和模型的预测概率如下：</p>
<ul>
<li>真实标签 <span class="math inline">\(y\)</span>: 猫: 1 狗: 0 兔子: 0
<ul>
<li>这可以表示为 [1,0,0]</li>
</ul></li>
<li>模型预测概率 <span class="math inline">\(\hat{y}\)</span>: 猫: 0.7
狗: 0.2 兔子: 0.1
<ul>
<li>这可以表示为 [0.7,0.2,0.1]</li>
</ul></li>
</ul>
<p>现在我们可以使用交叉熵损失公式来计算损失：<span
class="math inline">\(L_{\text{task}} = -\sum_{i=0}^{2} y^i
\log(\hat{y}^i)\)</span></p>
<p>带入具体的值：<span class="math inline">\(L_{\text{task}} = -[1 \cdot
\log(0.7) + 0 \cdot \log(0.2) + 0 \cdot \log(0.1)]≈0.3567\)</span></p>
<p>这个值表示模型的预测与真实标签之间的差异。一般来说，损失值越小，说明模型的预测越准确。</p>
<h3 id="想法">想法：</h3>
<p>1.特征解耦+迁移子空间for共享特征+BLS(增量)for差异特征</p>
<p>2.现有方法中，目标域样本均假设由部分源域样本线性组合，但是目标域样本应由<strong>同类的源域样本</strong>组合而成（<strong>伪标签）</strong></p>
<p>3.宽度学习加迁移学习调研</p>
<ol start="4" type="1">
<li><span class="math display">\[
\min_{W,P,T} \operatorname{Tr}(W^T X^T M X W) + \gamma \|W-PT\|_F^2 +
\lambda \| X_sP  - Y_S \|_F^2\\
\]</span></li>
</ol>
<p><span class="math display">\[
\min_{W,P,T} \operatorname{Tr}(W^T X^T M X W) + \gamma \|W-TP\|_F^2 +
\lambda \| X_sP  - Y_S \|_F^2\\
\]</span></p>
<h3 id="论文理解">论文理解：</h3>
<h5
id="discriminative-transfer-subspace-learning-via-low-rank-and-sparse-representation2017">1.Discriminative
Transfer Subspace Learning via Low-Rank and Sparse
Representation(2017)</h5>
<ul>
<li><p><strong>提出背景：</strong>在迁移学习中，训练数据和测试数据分别来自两类域：源域和目标域。这两个领域的数据通常共享相同的任务，但遵循<strong>不同的分布</strong>。在大多数情况下，只有一个目标域，而可能存在单个或多个源域。</p></li>
<li><p><strong>提出背景：</strong>先前工作可以分为两类，其一是修改数据的表示，存在以下问题：1）由于分布不同，很难捕获数据的内在结构，例如数据的<strong>全局和局部结构</strong>；2）对包含<strong>噪声</strong>数据的数据进行同等对待，影响模型的鲁棒性；3）大多数此类方法只关注如何改变数据的表示，而忽略了将分类器设计和改变数据表示的方法<strong>集成</strong>为一项任务可以更好地解决问题。其二是修改已经训练好的模型参数，在这种方法中，数据是固定的，但<strong>决策边界</strong>允许改变</p></li>
<li><p><strong>方法创新：</strong></p>
<figure>
<img
src="https://gitee.com/sk4772/photo/raw/master/photo/20241203100345864.png"
alt="image-20241203100345430" />
<figcaption aria-hidden="true">image-20241203100345430</figcaption>
</figure></li>
</ul>
<p>目标函数： <span class="math display">\[
\begin{align}
    &amp;\min_{P, Z, E, M} \quad \frac{1}{2} \phi(P, Y, X_s) + \|Z\|_* +
\alpha \|Z\|_1 + \beta \|E\|_1 \\
    &amp;\text{s.t.} \quad P^\top X_t = P^\top X_s Z + E, \\
    &amp;\quad \quad \phi = \|P^\top X_s - (Y + B \odot M)\|_F^2, \quad
M \geq 0
\end{align}
\]</span> 其中第一项使用了标签拖拽，增强判别能力，<span
class="math inline">\(\boldsymbol
P\)</span>表示变换矩阵，用于将源域样本和目标域的样本变换到子空间内；与此同时它还负责将源域样本变换到柔性标签空间内<code>（和松弛图那里感觉类似，然后限制了变换矩阵的灵活性，但是又不仅相同，这里是为了在子空间内源域样本尽可能可分，增强判别性）</code>。此外<span
class="math inline">\(\boldsymbol{Z}\)</span>表示重建矩阵，也就是说经过变换后，目标域的样本可以由源域样本通过线性组合得到，也就是表示在子空间内源域样本和目标域样本会很好地交错在一起，这也是我们所提迁移学习模型的目的。此外重构矩阵具有低秩的结构，因为目标域内样本在变换后由源域内同类样本线性组合而成。</p>
<ul>
<li><p><strong>实验验证：</strong></p>
<p>数据集：COIL 20 , MSRC, VOC 2007 , CMU PIE , Office, Caltech-256 and
Extended Yale B</p>
<p>实验方法：通过目标函数获得变换矩阵P，使用P分别得到源数据和目标数据的变换结果；使用1-Nearest
neighbor classifier（NN）或support vector
machine（SVM）对目标域数据的转换结果进行分类。换句话说，获得的变换矩阵P仅用于生成源域和目标域数据的特征，并通过传统分类器NN和SVM进行分类。</p>
<p>结果：</p>
<p>COIL20：划分为两个子集COIL1和COIL2,其中在COIL 1 包含在 [0°, 85°] ∪
[180°, 265°]（象限 1 和 3）方向拍摄的所有图像 [
39]，因此所有图像的数量为 720。COIL 2 包含在 [90°, 175°] ∪ [270°,
355°]（象限 2 和 4）方向拍摄的所有图像，所有图像的数量为
720,构造了两个分布相对不同的子集。</p>
<figure>
<img
src="https://gitee.com/sk4772/photo/raw/master/photo/20241203091550295.png"
alt="image-20241126161032411" />
<figcaption aria-hidden="true">image-20241126161032411</figcaption>
</figure>
<p><strong>MSRC数据集</strong>包含由18个类别标记的4323张图像，由微软剑桥研究院提供。
<strong>VOC 2007 数据集</strong>包含 5011 张图像，注释有 20
个概念。这两个数据集共享 6
个语义类：飞机、自行车、鸟、汽车、牛、羊。选择MSRC中的所有1269张图像形成源域，并选择VOC2007中的所有1530张图像形成目标域（MSRC
vs VOC，M→V））;然后我们将数据集与另一个数据集交换：VOC vs MSRC
(V→M)。所有图像的长度统一重新缩放为256像素，并使用VLFeat开源包提取128维密集SIFT（DSIFT）特征。然后利用K-means聚类得到240维的码本。这样，训练和测试数据就被构建为共享相同的标签集和特征空间</p>
<figure>
<img
src="https://gitee.com/sk4772/photo/raw/master/photo/20241203091556455.png"
alt="image-20241126161126582" />
<figcaption aria-hidden="true">image-20241126161126582</figcaption>
</figure>
<h5 id="domain-separation-networks域分离网络">5.Domain Separation
Networks(域分离网络)</h5></li>
<li><p><strong>提出背景：</strong></p>
<p>大量数据的<strong>标注代价</strong>往往使机器学习算法应用于新任务或数据集的成本过高，规避这一成本的一种方法是在自动提供标记的合成数据上训练模型。</p></li>
<li><p><strong>提出背景：</strong>尽管这些模型很有吸引力，但它们往往无法从合成图像泛化到真实图像，因此需要采用领域适应算法来处理这些模型，然后才能成功应用。</p></li>
<li><p><strong>方法创新：</strong></p>
<figure>
<img
src="https://gitee.com/sk4772/photo/raw/master/photo/20241203091605526.png"
alt="image-20241126161203165" />
<figcaption aria-hidden="true">image-20241126161203165</figcaption>
</figure>
<p><span
class="math inline">\(X^s、X^t\)</span>分别记作源域目标域的样本数据；<span
class="math inline">\(h_c、h_p\)</span>分别记作共享特征以及私有特征;</p>
<p>共享权重编码器 <span class="math inline">\(Ec\)</span>(x)
用于捕捉给定输入样本中各领域共享的表示成分。私有编码器<span
class="math inline">\(Ep\)</span>(x)（每个域一个）学习捕捉特定域的表示成分。共享解码器通过使用私有表征和源表征来重建输入样本。利用<strong>软子空间正交性约束</strong>
<span class="math inline">\(L_{dierence}\)</span>
将私有和共享表示成分分开，而利用相似性损失 <span
class="math inline">\(L_{similarity}\)</span>
保持共享表示成分的相似性。</p>
<p>损失函数Loss构建： <span class="math display">\[
L=L_{task}+\alpha{L}_{recon~}+\beta{L}_{difference}+\gamma{L}_{similarity}
\]</span> <span
class="math inline">\(\mathrm{L_{task}}\)</span>表示分类预测误差，<span
class="math inline">\(L_{dierence}\)</span>表示域之间的不同差异分离共享特征和独有特征，<span
class="math inline">\(L_{similarity}\)</span>
用于将源域与目标域的共享特征更好地交错。 <span class="math display">\[
L_{\text{task}} = -\sum_{i=0}^{n} y_i \log y_i
\]</span>
使用交叉熵损失函数去衡量预测值与实际值得差异，主要目的是衡量预测概率分布
与真实分布之间的差异。交叉熵损失越小，表示模型的预测越接近真实的标签分布。交叉熵损失多用于多分类多标签任务，目前，我们的工作主要集中于多分类单标签中，类似于咱们使用的“<span
class="math inline">\(Y-AW\)</span>”。 <span class="math display">\[
\mathcal{L}_{\text{recon}} = \sum_{i=1}^{N_s}
\mathcal{L}_{\text{si\_mse}}(\mathbf{x}_i^s, \hat{\mathbf{x}}_i^s) +
\sum_{i=1}^{N_t} \mathcal{L}_{\text{si\_mse}}(\mathbf{x}_i^t,
\hat{\mathbf{x}}_i^t)
\]</span></p>
<p><span class="math display">\[
\mathcal{L}_{\text{si\_mse}}(\mathbf{x}, \hat{\mathbf{x}}) = \frac{1}{k}
\|\mathbf{x} - \hat{\mathbf{x}}\|_2^2 - \frac{1}{k^2} \left( [\mathbf{x}
- \hat{\mathbf{x}}] \cdot \mathbf{1}_k \right)^2,
\]</span></p>
<p>使用比例不变均方误差去分析源数据与重建数据的差异。在重建任务（如图像重建或信号重建）中，传统的均方误差（MSE）通常被用来衡量模型生成的输出与目标之间的差异。然而，MSE
可能会有一个问题：它会对预测值的绝对大小非常敏感。因此，如果模型输出的预测结果在比例上正确（即，形状和结构与目标相似，但颜色或强度有所偏移），MSE
仍会产生较大的损失。这会导致模型在优化时，不仅关注形状和结构的准确性，还会尝试拟合输入的绝对尺度或强度。<strong>比例不变均方误差（Scale-Invariant
MSE, SIMSE）</strong>
则不同。它专注于预测值与目标值之间的相对差异，忽略了绝对的强度差异。SIMSE
通过去除预测值和目标值之间的整体偏移来衡量误差，确保模型更关注结构和形状的还原，而不是绝对的颜色或强度。因此，SIMSE
在像素对之间的相对差异上更敏感，而不会因整体的亮度或比例不同而产生额外惩罚。
<span class="math display">\[
\begin{equation}
\mathcal{L}_{\text{difference}} = \left\| H_{c}^{s\top} H_{p}^{s}
\right\|_{F}^{2} + \left\| H_{c}^{t\top} H_{p}^{t} \right\|_{F}^{2},
\end{equation}
\]</span> <span
class="math inline">\(L_{difference}\)</span>用于鼓励<strong>共享编码器和专用编码器</strong>对输入的不同方面进行编码，从而分离数据的<strong>共享特征以及私有特征</strong>。使用正交约束，使得共享特征与私有特征的内积尽可能小，增大两者的独立性。
<span class="math display">\[
\begin{equation}
    \mathcal{L}_{\text{similarity }}^{\text{MMD}}=
\frac{1}{(N^{s})^{2}}\sum_{i,j=0}^{N^{s}}\kappa(\mathbf{h}_{ci}^{s},\mathbf{h}_{cj}^{s})-\frac{2}{N^{s}N^{t}}\sum_{i,j=0}^{N^{s},N^{t}}\kappa(\mathbf{h}_{ci}^{s},\mathbf{h}_{cj}^{t})+\frac{1}{(N^{t})^{2}}\sum_{i,j=0}^{N^{t}}\kappa(\mathbf{h}_{ci}^{t},\mathbf{h}_{cj}^{t})
\end{equation}
\]</span></p>
<p><span class="math display">\[
\begin{equation}
    \mathcal{L}_{\text{similarity}}^{\text{DANN}}=\sum_{i=0}^{N_s+N_t}\left\{d_i\log\hat{d_i}
+ (1-d_i)\log(1-\hat{d_i})\right\}.
\end{equation}
\]</span></p>
<p>使用MMD衡量源域和目标域之间共同特征的差异；使用反向的交叉熵损失函数，随着迭代的增加Loss增加，具体来说，训练一个专门的分类器，主要用于区分样本来自于源域还是目标域，不过训练的目的并不是正确分类，而是让分类器无法区分样本来自哪个域。</p></li>
</ul>
<h5
id="domain-invariant-and-class-discriminative-feature-learning-for-visual-domain-adaptation2018">2.Domain
Invariant and Class Discriminative Feature Learning for Visual Domain
Adaptation(2018)</h5>
<figure>
<img
src="https://gitee.com/sk4772/photo/raw/master/photo/20241203091614077.png"
alt="image-20241126161927877" />
<figcaption aria-hidden="true">image-20241126161927877</figcaption>
</figure>
<ul>
<li><p><strong>提出背景：</strong>利用标记好的样本数据解决无标签样本，因为为样本打标签的过程是耗时昂给的。</p></li>
<li><p><strong>存在缺点：</strong>a）先前工作大多利用MMD等方法减少域之间的<strong>边缘分布</strong>，但不同域之间的<strong>条件分布</strong>也是存在差异的；b)
除此之外，仅减少域之间的差异是不足够的，因为减少差异的同时会降低数据的判别性，即不同类的样本变换到子空间后可能会相互靠近，影响分类器性能。</p></li>
<li><p><strong>方法创新：</strong></p>
<p>1.MMD减小域之间的边缘分布： <span class="math display">\[
\begin{aligned}
\mathcal{L}_{MMD}^{(0)}&amp;
=\left\|\frac{1}{n_{s}}\sum_{i=1}^{n_{s}}z_{Si}-\frac{1}{n_{t}}\sum_{j=1}^{n_{t}}z_{Tj}\right\|^{2}
\\
&amp;=\left\|\frac{1}{n_{s}}\sum_{i=1}^{n_{s}}\mathbf{P}^{\top}\boldsymbol{x}_{Si}-\frac{1}{n_{t}}\sum_{j=1}^{n_{t}}\mathbf{P}^{\top}\boldsymbol{x}_{Tj}\right\|^{2}
\\
&amp;=\mathbf{Tr}\left(\mathbf{P}^\top\mathbf{X}\mathbf{W}_0\mathbf{X}^\top\mathbf{P}\right),
\end{aligned}
\]</span>
2.减少域之间的条件分布，因为目标域数据不存在标签数据，导致难以对齐条件分布，因此文章使用伪标签进行对齐，通过迭代优化伪标签：
$$</p>
<p>$$ 3.分布建模</p>
<p>4.类内相似性建模</p>
<p>5.类间差异性建模</p>
<p>6.类内相似性和差异性统一</p></li>
</ul>
<h5
id="robust-transferable-subspace-learning-for-cross-corpus-facial-expression-recognition2020">3.Robust
Transferable Subspace Learning for Cross-Corpus Facial Expression
Recognition(2020)</h5>
<figure>
<img
src="https://gitee.com/sk4772/photo/raw/master/photo/20241203091621174.png"
alt="image-20241126161959952" />
<figcaption aria-hidden="true">image-20241126161959952</figcaption>
</figure>
<ul>
<li><p><strong>提出背景：</strong>表情识别在严格条件获取的表情图像下可以很好的效果，但现实中表情图像往往来自于不同的设备或者环境，因此会存在不同域的数据，从而导致模型性能严重下降</p></li>
<li><p><strong>存在缺点：</strong>大多数方法仅通过<strong>MMD</strong>考虑数据之间的全局距离度量（global
distance metric）,这样虽然可以拉近不同域之间的距离
，但也会将不同类样本的距离拉近，降低模型的判别能力。</p></li>
<li><p><strong>方法创新：</strong></p>
<p>1.引入全局度量算法,
有效地减少<strong>特征分布差异</strong>并获得<strong>鲁棒</strong>不变特征表示</p>
<p>使用marginal MMD和conditional MMD，</p>
<p>2.考虑数据的<strong>判别</strong>知识以及数据本地的流形结构，提出了新的<strong>local
discriminative distance metric</strong></p>
<p>​
首先在原先MMD的基础(<strong>全局结构</strong>)上添加条件MMD去考虑数据的<strong>局部结构</strong>即：
<span class="math display">\[
\min_{P} \operatorname{Tr}\left(P^T X (M_0 + M_C) X^T P\right) + \gamma
\|P\|_F^2
\]</span> 其中<span
class="math inline">\(M_0\)</span>表述传统的MMD,<span
class="math inline">\(M_C\)</span>表示条件MMD，由下式表示： <span
class="math display">\[
\operatorname{Tr}(P^T X M_C X^T P) = \sum_{c=1}^{C} \left\|
\frac{1}{N_S^c} \sum_{x_i \in \mathcal{D}_S^{(c)}} P^T x_i -
\frac{1}{N_T^c} \sum_{x_j \in \mathcal{D}_T^{(c)}} P^T x_j \right\|^2
\]</span>
这个式子就是将同类样本取均值做MMD，其中关键之处是使用<strong>伪标签</strong>作为目标域的标签，因为原本的目标域是无标签的。</p>
<p>​
其次，使用<strong>标签拖拽</strong>增加判别能力，并构造源域内部图以及两域之间图即，他们的权重定义如下：
$$</p>
<span class="math display">\[\begin{aligned}
{(W^S_w)}_{ij} =
\begin{cases}
1, &amp; \text{if } i \neq j, y_{S_i} = y_{S_j} \\
0, &amp; \text{otherwise}
\end{cases}
\\

{(W^T_w)}_{ij} =
\begin{cases}
1, &amp; \text{if } i \neq j, \hat{y}_{T_i} = \hat{y}_{T_j} \\
0, &amp; \text{otherwise}
\end{cases}
\end{aligned}\]</span>
<p><span class="math display">\[
这里源域使用真实标签，目标域使用伪标签进行图的构造
\]</span></p>
<span class="math display">\[\begin{aligned}
(W^{ST}_w)_{ij} =
\begin{cases}
1, &amp; \text{if } x_j \in N^c_k(x_i) \text{ or } x_i \in N^c_k(x_j) \\
0, &amp; \text{otherwise}
\end{cases}
\\
(W^{TS}_w)_{ji} =
\begin{cases}
1, &amp; \text{if } x_i \in N^c_k(x_j) \text{ or } x_j \in N^c_k(x_i) \\
0, &amp; \text{otherwise}
\end{cases}
\end{aligned}\]</span>
<p><span class="math display">\[
这里通过判断最近邻设置图，构造最终的两个权重矩阵$W_w$和$W_b$
\]</span></p>
<span class="math display">\[\begin{aligned}
W_w &amp;= \begin{bmatrix}
W^S &amp; W^{ST} \\
W^{TS} &amp; W^T
\end{bmatrix}
\\
W_b &amp;= \begin{bmatrix}
W^S &amp; 0 \\
0 &amp; W^T
\end{bmatrix}
\end{aligned}\]</span>
<p><span class="math display">\[
通过此构造拉普拉斯矩阵$L_w = D_w - W_w, \quad L_b = D_b -
W_b$，并以此构造流形正则项：
\]</span> <em>{P} (P^T X (L_w - L_b) X^T P) = </em>{P} (P^T X L X^T P)
$$ 其实这两项就是<strong>域内图以及域间图</strong>的合并项。</p>
<p>最终目标函数为 $$ _{P,V} (P^T X (M + L) X^T P) + |P|_F^2 + |P^T X_S -
(Y_S + B V)|_F^2\</p>
<p> P^T P = I, V $$</p></li>
<li></li>
</ul>
<h5
id="balanced-discriminative-transfer-feature-learning-for-visual-domain-adaptation2021">4.Balanced
Discriminative Transfer Feature Learning for Visual Domain
Adaptation（2021）</h5>
<p>​
动机：迁移学习中使用特征匹配可以有效缓解域迁移过程中存在的问题但同等对待<strong>边缘分布和条件分布</strong>，忽视了两者之间的关系，除此之外域内的判别信息也被忽视。</p>
<p>方法：</p>
<ol type="1">
<li>平衡边缘分布以及条件分布：通过MMD分别最小化边缘分布以及条件分布，至于两者之间的权重分配，当源域目标域之间的差距大时，更加注重边缘分布；而当两者很相似时，更加注重条件分布</li>
<li>判别信息：通过最小化类内相似性以及最大化类间差异性获得，注意目标域使用伪标签（pseudo
label）</li>
<li>目标函数:</li>
</ol>
<h5
id="discriminative-fisher-embedding-dictionary-transfer-learning-for-object-recognition2023">5.Discriminative
Fisher Embedding Dictionary Transfer Learning for Object
Recognition（2023）</h5>
<p>问题：目标域数据缺乏可用的标签</p>
<p>解决思想：将源域以及目标域数据投影到统一的子空间内；在此空间内，目标域数据可由源域数据组合表示，他们在此空间内可以很好地交错。两者分布大致相同，因此通过训练源域数据得到的模型可以很好地分类目标域数据.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">以往方法缺陷</th>
<th>补足</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">1.难以捕获数据内在结构</td>
<td></td>
</tr>
<tr>
<td style="text-align: left;">2.没有考虑噪声</td>
<td></td>
</tr>
<tr>
<td
style="text-align: left;">3.忽略了将更改数据表示和分类器设计统一</td>
<td></td>
</tr>
</tbody>
</table>
<ul class="task-list">
<li><label><input type="checkbox" />2.Dynamic Double Classifiers
Approximation for Cross-Domain Recognition（2022）</label></li>
</ul>
<h3 id="实验">实验</h3>
<h5 id="caltech256-and-office">1.Caltech256 and Office</h5>
<p>Caltech256 是一个标准的对象识别数据集. 分 别从 Office 和 Caltech256
数据集中提取 1 410 幅 和 1 123 幅图像, 在 Office 中, A 子集含有 958 幅图
像, W 子集含有 295 幅图像, D 子集含有 157 幅图 像, 每幅图像被提取 SURF
特征并量化成 800 维的 向量, 因此两种不同的数据可以具有相同的特征空
间.</p>
<table>
<thead>
<tr>
<th>任务/方法</th>
<th>BLS</th>
<th>DABLS</th>
<th>CD-CDBN</th>
<th>SS-BLS</th>
<th>TCA</th>
<th>CDELM</th>
</tr>
</thead>
<tbody>
<tr>
<td>A→C</td>
<td>20.82</td>
<td>44.29</td>
<td>35.56</td>
<td>42.16</td>
<td>40.78</td>
<td>31.67</td>
</tr>
<tr>
<td>A→D</td>
<td>17.83</td>
<td>42.06</td>
<td>33.79</td>
<td>39.40</td>
<td>31.85</td>
<td>32.48</td>
</tr>
<tr>
<td>A→W</td>
<td>19.61</td>
<td>42.09</td>
<td>27.46</td>
<td>40.61</td>
<td>37.63</td>
<td>31.47</td>
</tr>
<tr>
<td>C→A</td>
<td>29.16</td>
<td>51.68</td>
<td>38.78</td>
<td>49.67</td>
<td>44.89</td>
<td>44.99</td>
</tr>
<tr>
<td>C→D</td>
<td>24.84</td>
<td>45.85</td>
<td>36.94</td>
<td>44.20</td>
<td>45.84</td>
<td>35.37</td>
</tr>
<tr>
<td>C→W</td>
<td>20.46</td>
<td>47.79</td>
<td>35.54</td>
<td>45.74</td>
<td>36.61</td>
<td>38.92</td>
</tr>
<tr>
<td>D→A</td>
<td>32.42</td>
<td>36.73</td>
<td>28.34</td>
<td>35.57</td>
<td>31.52</td>
<td>30.61</td>
</tr>
<tr>
<td>D→C</td>
<td>30.03</td>
<td>32.47</td>
<td>26.79</td>
<td>30.19</td>
<td>32.50</td>
<td>28.96</td>
</tr>
<tr>
<td>D→W</td>
<td>79.98</td>
<td>80.06</td>
<td>50.78</td>
<td>79.11</td>
<td>87.12</td>
<td>76.95</td>
</tr>
<tr>
<td>W→A</td>
<td>34.61</td>
<td>40.01</td>
<td>30.89</td>
<td>37.51</td>
<td>30.69</td>
<td>35.55</td>
</tr>
<tr>
<td>W→C</td>
<td>31.73</td>
<td>36.50</td>
<td>27.26</td>
<td>35.29</td>
<td>27.16</td>
<td>32.03</td>
</tr>
<tr>
<td>W→D</td>
<td>80.81</td>
<td>82.73</td>
<td>50.42</td>
<td>80.89</td>
<td>90.45</td>
<td>78.99</td>
</tr>
<tr>
<td>平均值</td>
<td>35.19</td>
<td>48.52</td>
<td>35.21</td>
<td>46.69</td>
<td>45.38</td>
<td>41.50</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th>任务/方法</th>
<th>DABLS</th>
</tr>
</thead>
<tbody>
<tr>
<td>COIL20_1-&gt;COIL_2</td>
<td>88.12</td>
</tr>
<tr>
<td>COIL20_2-&gt;COIL_1</td>
<td>84.72</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th>任务/方法</th>
<th>DABLS</th>
</tr>
</thead>
<tbody>
<tr>
<td>ImageNet-&gt;VOC2007</td>
<td>67.83</td>
</tr>
<tr>
<td>VOC2007-&gt;ImageNet</td>
<td>77.87</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th>任务/方法</th>
<th>DABLS</th>
</tr>
</thead>
<tbody>
<tr>
<td>MNIST-&gt;USPS</td>
<td>68.54</td>
</tr>
<tr>
<td>USPS-&gt;MNIST</td>
<td>50.13</td>
</tr>
</tbody>
</table>
]]></content>
      <categories>
        <category>论文阅读</category>
      </categories>
      <tags>
        <tag>域自适应</tag>
        <tag>MMD</tag>
        <tag>迁移学习</tag>
      </tags>
  </entry>
</search>
