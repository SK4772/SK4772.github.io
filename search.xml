<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>论文写作注意事项—Csk</title>
    <url>/2017/05/26/%E8%AE%BA%E6%96%87%E5%86%99%E4%BD%9C%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9%E2%80%94Csk/</url>
    <content><![CDATA[<h1 id="论文写作注意事项—Csk"><a href="#论文写作注意事项—Csk" class="headerlink" title="论文写作注意事项—Csk"></a>论文写作注意事项—Csk</h1><h4 id="文章撰写所需软件："><a href="#文章撰写所需软件：" class="headerlink" title="文章撰写所需软件："></a>文章撰写所需软件：</h4><p>latex安装；Winedt: Latex代码编辑器</p>
<p><img src="https://gitee.com/sk4772/photo/raw/master/photo/20241203092330619.png" alt="image-20241203092330561"></p>
<p>JabRef:  参考文献管理</p>
<p>MATLAB: 代码（实验，绘图）</p>
<p>绘图：PPT，MATLAB，Python</p>
<p>文献阅读管理：Zotero, 知云等</p>
<p>文献网站：谷歌学术，百度学术，<a href="https://www.scidown.cn/">Scidown</a>(文献下载)，<a href="aminer.cn">AMiner</a>，<a href="sci-hub.se">Sci-hub</a>（文献下载），<a href="http://spis.hnlat.com/">SPIS</a>，<a href="https://www.ablesci.com/">科研通</a></p>
<p>代码查找：Github, <a href="https://paperswithcode.com/">Paperwithcode</a></p>
<p>大模型：ChatGPT，kimi</p>
<h4 id="行文规范"><a href="#行文规范" class="headerlink" title="行文规范"></a>行文规范</h4><h5 id="1-缩写"><a href="#1-缩写" class="headerlink" title="1.缩写"></a>1.缩写</h5><p>文章中需要多次出现时，第一次使用全称，后文使用缩写；</p>
<p>摘要中尽量避免出现缩写，影响读者阅读；</p>
<p>摘要中的缩写与文章中的缩写相互独立，举例：BLS在摘要中出现过，正文中第一次使用时仍需使用全称，随后在再使用缩写；</p>
<h5 id="2-标点符号"><a href="#2-标点符号" class="headerlink" title="2.标点符号"></a>2.标点符号</h5><p>标点前不空格，标点后空格</p>
<p><strong>易犯错：当一句话未结束时使用逗号（特指公式）</strong></p>
<p>当公式中出现新的变量，符号时进行需解释说明</p>
<p><strong>文章前后的标量字符要统一</strong>，如X，Y的维度要与相对应变量的维度统一</p>
<h5 id="3-段落"><a href="#3-段落" class="headerlink" title="3.段落"></a>3.段落</h5><p>尽量避免多次分段且每段篇幅短，影响观感</p>
<h5 id="4-句子"><a href="#4-句子" class="headerlink" title="4.句子"></a>4.句子</h5><p>避免出现错别字，单复数形式，时态错误等语法错误，<strong>可以使用GPT,word（检查错别字）等</strong></p>
<p>句子中的数字不能单纯打出来，以latex代码形式出现</p>
<h5 id="5-参考文献"><a href="#5-参考文献" class="headerlink" title="5.参考文献"></a>5.参考文献</h5><p>参考文献中近三年的文章引用至少三分之一左右；</p>
<p>引用一些所投期刊的文章</p>
<h5 id="6-文献降重"><a href="#6-文献降重" class="headerlink" title="6.文献降重"></a>6.文献降重</h5><p>GPT降重指令及已有<a href="https://chatgpt.com/share/671a42e5-0cc8-8005-af71-c77efd5e7900">对话链接</a>：我将给你两段文字，你给出他们之间的重复部分，并对段1文本中的句子结构进行改写调整，通过采用不同的句型和语法结构，避免出现连续四个字与段2相同的情况，以增强文本的多样性和学术性。</p>
]]></content>
      <categories>
        <category>论文写作</category>
      </categories>
      <tags>
        <tag>入门</tag>
      </tags>
  </entry>
  <entry>
    <title>迁移学习综述</title>
    <url>/2024/12/01/%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E7%BB%BC%E8%BF%B0/</url>
    <content><![CDATA[<h1 id="迁移学习"><a href="#迁移学习" class="headerlink" title="迁移学习"></a>迁移学习</h1><h3 id="前置知识："><a href="#前置知识：" class="headerlink" title="前置知识："></a>前置知识：</h3><h4 id="1-边缘概率分布和条件概率分布"><a href="#1-边缘概率分布和条件概率分布" class="headerlink" title="1.边缘概率分布和条件概率分布"></a>1.边缘概率分布和条件概率分布</h4><p>​	在迁移学习中，边缘概率分布和条件概率分布是两个重要的概念。<strong>边缘概率分布</strong>（Marginal Probability Distribution），即P(X)，在迁移学习中是指的是数据的特征分布。P(x)不同是说数据的产生机制不一样，比如不同角度、光照或背景的图像，不同被试者产生的生理数据、行为数据，它们都服从不同的特征分布，即边缘概率分布不一致。在迁移学习中，只要源域和目标域数据服从不同的分布规律，我们就认为二者存在边缘概率分布差异，这种差异被称为分布偏移或领域漂移（domain shift）。<strong>条件概率分布</strong>（Conditional Probability Distribution），即P(y|x)，在迁移学习中是指给定特征的条件下，标签的分布。在理想情况下，源域和目标域的条件概率分布是相同的。然而，在现实中并不总是成立。比如，不同被试者的生理数据通常不一样；而且即使是相同被试者，在不同状态或者时间下，进行相同的动作，生理数据也存在差异。另外，在迁移学习中，理解边缘概率分布和条件概率分布的差异是非常重要的，因为这可以帮助我们选择合适的迁移学习策略。例如，如果源域和目标域在边缘概率分布上有较大差异，但在条件概率分布上差异较小，那么我们可能会选择使用特征选择或者特征转换的方法来进行迁移学习。反之，如果源域和目标域在条件概率分布上有较大差异，那么我们可能需要使用更复杂的迁移学习方法，例如重新标注一些目标域的数据，或者使用对抗性训练等方法来解决这个问题。</p>
<p>​	我们通常解决的是边缘概率分布以及条件概率分布的不同情况即$P_s(X)\neq P_t(X)$且$P_s(Y|X)\neq P_t(Y|X)$。源域和目标域的数据分布存在差异即$P_s(X,Y)\neq P_t(X,Y)$，通过贝叶斯公式，可以将这个联合概率分解为：$P(X,Y)&#x3D; P(Y|X)P(X)$ 因此可以将源域和目标域数据分布不同转化为边缘概率分布和条件概率分布。</p>
<h4 id="2-MMD"><a href="#2-MMD" class="headerlink" title="2.MMD"></a>2.MMD</h4><p>​	既然存在着分布上的差异，那么在迁移学习中便要尽可能减少分布之间的差异。其中所必须思考的问题是如何度量这种差异，只有度量出差异后，才能尽可能减少分布上的差异。</p>
<p>首先，我们考虑如何描述一个随机变量，最直接的方法就是给出它的概率分布函数 f(x) 。一些简单的分布可以这么干，比如正态分布给出均值和方差就可以确定，但是对于一些<strong>复杂的、高维的随机变量</strong>，我们无法给出它们的分布函数。这时候我们可以用随机变量的矩来描述一个随机变量，比如一阶中心矩是均值，二阶中心矩是方差等等。如果两个分布的均值和方差都相同的话，它们应该很相似，比如同样均值和方差的高斯分布和拉普拉斯分布。但是很明显，均值和方差并不能完全代表一个分布，这时候我们就需<strong>要更高阶的矩</strong>来描述一个分布[<a href="https://zhuanlan.zhihu.com/p/163839117#ref_1">1]</a>。举个例子，就好比描述人一样，如果两个人身高、轮廓都一样，我们会说这两个人很像。但是如果要说这两个人是一个人的话，我们如要更多的信息，比如血型、DNA等更加复杂的信息。</p>
<p>而MMD的基本思想就是，如果两个随机变量的任意阶都相同的话，那么两个分布就是一致的。而当两个分布不相同的话，那么使得<strong>两个分布之间差距最大的那个矩</strong>应该被用来作为度量两个分布的标准。</p>
$$
\begin{equation*}
    \begin{split}
        &\left\|\frac{1}{n_{s}} \sum_{i=1}^{n_{s}} \mathbf{A}^{\mathrm{T}} \mathbf{x}_{i}-\frac{1}{n_{t}} \sum_{j=n_{s}+1}^{n_{s}+n_{t}} \mathbf{A}^{\mathrm{T}} \mathbf{x}_{j}\right\|^{2}\\
        &=\left\|\frac{1}{n_{s}} \mathbf{A}^{\mathrm{T}} \begin{bmatrix}
\mathbf{x}_1 & \mathbf{x}_2 & \cdots & \mathbf{x}_{n_s} 
\end{bmatrix}_{1 \times n_s} \begin{bmatrix}
1\\ 
1\\ 
\vdots\\ 
1
\end{bmatrix}_{n_s \times 1} -\frac{1}{n_{t}} \mathbf{A}^{\mathrm{T}} \begin{bmatrix}
\mathbf{x}_1 & \mathbf{x}_2 & \cdots & \mathbf{x}_{n_t} 
\end{bmatrix}_{1 \times n_t} \begin{bmatrix}
1\\ 
1\\ 
\vdots\\ 
1
\end{bmatrix}_{n_t \times 1}\right\|^{2}\\
&=\operatorname{tr} \left(\frac{1}{n^2_{s}} \mathbf{A}^{\mathrm{T}} \mathbf{X}_s \mathbf{1} (\mathbf{A}^{\mathrm{T}} \mathbf{X}_s \mathbf{1})^{\mathrm{T}} +\frac{1}{n^2_{t}} \mathbf{A}^{\mathrm{T}} \mathbf{X}_t \mathbf{1} (\mathbf{A}^{\mathrm{T}} \mathbf{X}_t \mathbf{1})^{\mathrm{T}} - \frac{1}{n_s n_t} \mathbf{A}^{\mathrm{T}} \mathbf{X}_s \mathbf{1} (\mathbf{A}^{\mathrm{T}} \mathbf{X}_t \mathbf{1})^{\mathrm{T}} - \frac{1}{n_s n_t} \mathbf{A}^{\mathrm{T}} \mathbf{X}_t \mathbf{1} (\mathbf{A}^{\mathrm{T}} \mathbf{X}_s \mathbf{1})^{\mathrm{T}}\right)\\
&=\operatorname{tr} \left(\frac{1}{n^2_{s}} \mathbf{A}^{\mathrm{T}} \mathbf{X}_s \mathbf{1} \mathbf{1}^{\mathrm{T}} \mathbf{X}_s^{\mathrm{T}} \mathbf{A} +\frac{1}{n^2_{t}} \mathbf{A}^{\mathrm{T}} \mathbf{X}_t \mathbf{1} \mathbf{1}^{\mathrm{T}} \mathbf{X}_t^{\mathrm{T}} \mathbf{A} - \frac{1}{n_s n_t} \mathbf{A}^{\mathrm{T}} \mathbf{X}_s \mathbf{1} \mathbf{1}^{\mathrm{T}} \mathbf{X}_t^{\mathrm{T}} - \frac{1}{n_s n_t} \mathbf{A}^{\mathrm{T}} \mathbf{X}_t \mathbf{1} \mathbf{1}^{\mathrm{T}} \mathbf{X}_s^{\mathrm{T}} \right)\\
&=\operatorname{tr} \left[ \mathbf{A}^{\mathrm{T}} \left( \frac{1}{n^2_s} \mathbf{1}\mathbf{1}^{\mathrm{T}} \mathbf{X}_s^{\mathrm{T}} \mathbf{X}_s + \frac{1}{n^2_t} \mathbf{1}\mathbf{1}^{\mathrm{T}} \mathbf{X}_t^{\mathrm{T}} \mathbf{X}_t - \frac{1}{n_s n_t} \mathbf{1} \mathbf{1}^{\mathrm{T}} \mathbf{X}_s^{\mathrm{T}} \mathbf{X}_t - \frac{1}{n_s n_t} \mathbf{1} \mathbf{1}^{\mathrm{T}} \mathbf{X}_t^{\mathrm{T}} \mathbf{X}_s \right) \mathbf{A} \right]\\
&=\operatorname{tr} \left( \mathbf{A}^{\mathrm{T}} \begin{bmatrix}
\mathbf{X}_s & \mathbf{X}_t 
\end{bmatrix} \begin{bmatrix}
\frac{1}{n^2_s} \mathbf{1}\mathbf{1}^{\mathrm{T}} & \frac{-1}{n_s n_t} \mathbf{1}\mathbf{1}^{\mathrm{T}} \\ 
\frac{-1}{n_s n_t} \mathbf{1}\mathbf{1}^{\mathrm{T}} & \frac{1}{n^2_t} \mathbf{1}\mathbf{1}^{\mathrm{T}}
\end{bmatrix}  \begin{bmatrix}
\mathbf{X}_s \\ \mathbf{X}_t 
\end{bmatrix} \mathbf{A} \right)\\
&=\operatorname{tr} \left( \mathbf{A}^{\mathrm{T}} \mathbf{X} \mathbf{M} \mathbf{X}^{\mathrm{T}}  \mathbf{A} \right)
    \end{split}
\end{equation*}
$$

<h4 id="3-Global-distance-and-Local-distance"><a href="#3-Global-distance-and-Local-distance" class="headerlink" title="3.Global distance and Local distance:"></a>3.Global distance and Local distance:</h4><h4 id="4-判别信息"><a href="#4-判别信息" class="headerlink" title="4.判别信息"></a>4.判别信息</h4><h4 id="5交叉熵损失"><a href="#5交叉熵损失" class="headerlink" title="5交叉熵损失."></a>5交叉熵损失.</h4><p>​	假设我们有一个三类分类问题（例如，猫、狗和兔子），我们的模型需要对一张图片进行分类。我们设定真实的标签（one-hot 编码）和模型的预测概率如下：</p>
<ul>
<li>真实标签 $y$:  猫: 1     狗: 0     兔子: 0<ul>
<li>这可以表示为 [1,0,0]</li>
</ul>
</li>
<li>模型预测概率 $\hat{y}$: 猫: 0.7 狗: 0.2 兔子: 0.1<ul>
<li>这可以表示为 [0.7,0.2,0.1]</li>
</ul>
</li>
</ul>
<p>现在我们可以使用交叉熵损失公式来计算损失：$L_{\text{task}} &#x3D; -\sum_{i&#x3D;0}^{2} y^i \log(\hat{y}^i)$</p>
<p>带入具体的值：$L_{\text{task}} &#x3D; -[1 \cdot \log(0.7) + 0 \cdot \log(0.2) + 0 \cdot \log(0.1)]≈0.3567$</p>
<p>这个值表示模型的预测与真实标签之间的差异。一般来说，损失值越小，说明模型的预测越准确。</p>
<h3 id="想法："><a href="#想法：" class="headerlink" title="想法："></a>想法：</h3><p>1.特征解耦+迁移子空间for共享特征+BLS(增量)for差异特征</p>
<p>2.现有方法中，目标域样本均假设由部分源域样本线性组合，但是目标域样本应由<strong>同类的源域样本</strong>组合而成（<strong>伪标签）</strong></p>
<p>3.宽度学习加迁移学习调研</p>
<ol start="4">
<li>$$
\min_{W,P,T} \operatorname{Tr}(W^T X^T M X W) + \gamma \|W-PT\|_F^2 + \lambda \| X_sP  - Y_S \|_F^2\\
$$</li>
</ol>
$$
\min_{W,P,T} \operatorname{Tr}(W^T X^T M X W) + \gamma \|W-TP\|_F^2 + \lambda \| X_sP  - Y_S \|_F^2\\
$$



<h3 id="论文理解："><a href="#论文理解：" class="headerlink" title="论文理解："></a>论文理解：</h3><h5 id="1-Discriminative-Transfer-Subspace-Learning-via-Low-Rank-and-Sparse-Representation-2017"><a href="#1-Discriminative-Transfer-Subspace-Learning-via-Low-Rank-and-Sparse-Representation-2017" class="headerlink" title="1.Discriminative Transfer Subspace Learning via  Low-Rank and Sparse Representation(2017)"></a>1.Discriminative Transfer Subspace Learning via  Low-Rank and Sparse Representation(2017)</h5><ul>
<li><p><strong>提出背景：</strong>在迁移学习中，训练数据和测试数据分别来自两类域：源域和目标域。这两个领域的数据通常共享相同的任务，但遵循<strong>不同的分布</strong>。在大多数情况下，只有一个目标域，而可能存在单个或多个源域。</p>
</li>
<li><p><strong>提出背景：</strong>先前工作可以分为两类，其一是修改数据的表示，存在以下问题：1）由于分布不同，很难捕获数据的内在结构，例如数据的<strong>全局和局部结构</strong>；2）对包含<strong>噪声</strong>数据的数据进行同等对待，影响模型的鲁棒性；3）大多数此类方法只关注如何改变数据的表示，而忽略了将分类器设计和改变数据表示的方法<strong>集成</strong>为一项任务可以更好地解决问题。其二是修改已经训练好的模型参数，在这种方法中，数据是固定的，但<strong>决策边界</strong>允许改变</p>
</li>
<li><p><strong>方法创新：</strong></p>
<p><img src="https://gitee.com/sk4772/photo/raw/master/photo/20241203091516231.png" alt="image-20241203091515845"></p>
</li>
</ul>
<p>目标函数：</p>
$$
\begin{align}
    &\min_{P, Z, E, M} \quad \frac{1}{2} \phi(P, Y, X_s) + \|Z\|_* + \alpha \|Z\|_1 + \beta \|E\|_1 \\
    &\text{s.t.} \quad P^\top X_t = P^\top X_s Z + E, \\
    &\quad \quad \phi = \|P^\top X_s - (Y + B \odot M)\|_F^2, \quad M \geq 0
\end{align}
$$
<p>其中第一项使用了标签拖拽，增强判别能力，$\boldsymbol P$表示变换矩阵，用于将源域样本和目标域的样本变换到子空间内；与此同时它还负责将源域样本变换到柔性标签空间内<code>（和松弛图那里感觉类似，然后限制了变换矩阵的灵活性，但是又不仅相同，这里是为了在子空间内源域样本尽可能可分，增强判别性）</code>。此外$\boldsymbol{Z}$表示重建矩阵，也就是说经过变换后，目标域的样本可以由源域样本通过线性组合得到，也就是表示在子空间内源域样本和目标域样本会很好地交错在一起，这也是我们所提迁移学习模型的目的。此外重构矩阵具有低秩的结构，因为目标域内样本在变换后由源域内同类样本线性组合而成。</p>
<ul>
<li><p><strong>实验验证：</strong></p>
<p>数据集：COIL 20 , MSRC, VOC 2007 , CMU PIE , Office, Caltech-256 and Extended Yale B</p>
<p>实验方法：通过目标函数获得变换矩阵P，使用P分别得到源数据和目标数据的变换结果；使用1-Nearest neighbor classifier（NN）或support vector machine（SVM）对目标域数据的转换结果进行分类。换句话说，获得的变换矩阵P仅用于生成源域和目标域数据的特征，并通过传统分类器NN和SVM进行分类。</p>
<p>结果：</p>
<p>COIL20：划分为两个子集COIL1和COIL2,其中在COIL 1 包含在 [0°, 85°] ∪ [180°, 265°]（象限 1 和 3）方向拍摄的所有图像 [ 39]，因此所有图像的数量为 720。COIL 2 包含在 [90°, 175°] ∪ [270°, 355°]（象限 2 和 4）方向拍摄的所有图像，所有图像的数量为 720,构造了两个分布相对不同的子集。</p>
<p><img src="https://gitee.com/sk4772/photo/raw/master/photo/20241203091550295.png" alt="image-20241126161032411"></p>
<p><strong>MSRC数据集</strong>包含由18个类别标记的4323张图像，由微软剑桥研究院提供。 <strong>VOC 2007 数据集</strong>包含 5011 张图像，注释有 20 个概念。这两个数据集共享 6 个语义类：飞机、自行车、鸟、汽车、牛、羊。选择MSRC中的所有1269张图像形成源域，并选择VOC2007中的所有1530张图像形成目标域（MSRC vs VOC，M→V））;然后我们将数据集与另一个数据集交换：VOC vs MSRC (V→M)。所有图像的长度统一重新缩放为256像素，并使用VLFeat开源包提取128维密集SIFT（DSIFT）特征。然后利用K-means聚类得到240维的码本。这样，训练和测试数据就被构建为共享相同的标签集和特征空间</p>
<p><img src="https://gitee.com/sk4772/photo/raw/master/photo/20241203091556455.png" alt="image-20241126161126582"></p>
<h5 id="5-Domain-Separation-Networks-域分离网络"><a href="#5-Domain-Separation-Networks-域分离网络" class="headerlink" title="5.Domain Separation Networks(域分离网络)"></a>5.Domain Separation Networks(域分离网络)</h5></li>
<li><p><strong>提出背景：</strong></p>
<p>大量数据的<strong>标注代价</strong>往往使机器学习算法应用于新任务或数据集的成本过高，规避这一成本的一种方法是在自动提供标记的合成数据上训练模型。</p>
</li>
<li><p><strong>提出背景：</strong>尽管这些模型很有吸引力，但它们往往无法从合成图像泛化到真实图像，因此需要采用领域适应算法来处理这些模型，然后才能成功应用。</p>
</li>
<li><p><strong>方法创新：</strong></p>
<p><img src="https://gitee.com/sk4772/photo/raw/master/photo/20241203091605526.png" alt="image-20241126161203165"></p>
<p>$X^s、X^t$分别记作源域目标域的样本数据；$h_c、h_p$分别记作共享特征以及私有特征;</p>
<p>共享权重编码器 $Ec$(x) 用于捕捉给定输入样本中各领域共享的表示成分。私有编码器$Ep$(x)（每个域一个）学习捕捉特定域的表示成分。共享解码器通过使用私有表征和源表征来重建输入样本。利用<strong>软子空间正交性约束</strong> $L_{dierence}$ 将私有和共享表示成分分开，而利用相似性损失 $L_{similarity}$ 保持共享表示成分的相似性。</p>
<p>损失函数Loss构建：</p>
$$
L=L_{task}+\alpha{L}_{recon~}+\beta{L}_{difference}+\gamma{L}_{similarity}
$$
<p>$\mathrm{L_{task}}$表示分类预测误差，$L_{dierence}$表示域之间的不同差异分离共享特征和独有特征，$L_{similarity}$ 用于将源域与目标域的共享特征更好地交错。</p>
$$
L_{\text{task}} = -\sum_{i=0}^{n} y_i \log y_i
$$
<p>使用交叉熵损失函数去衡量预测值与实际值得差异，主要目的是衡量预测概率分布 与真实分布之间的差异。交叉熵损失越小，表示模型的预测越接近真实的标签分布。交叉熵损失多用于多分类多标签任务，目前，我们的工作主要集中于多分类单标签中，类似于咱们使用的“$Y-AW$”。</p>
$$
\mathcal{L}_{\text{recon}} = \sum_{i=1}^{N_s} \mathcal{L}_{\text{si\_mse}}(\mathbf{x}_i^s, \hat{\mathbf{x}}_i^s) + \sum_{i=1}^{N_t} \mathcal{L}_{\text{si\_mse}}(\mathbf{x}_i^t, \hat{\mathbf{x}}_i^t)
$$

$$
\mathcal{L}_{\text{si\_mse}}(\mathbf{x}, \hat{\mathbf{x}}) = \frac{1}{k} \|\mathbf{x} - \hat{\mathbf{x}}\|_2^2 - \frac{1}{k^2} \left( [\mathbf{x} - \hat{\mathbf{x}}] \cdot \mathbf{1}_k \right)^2,
$$

<p>使用比例不变均方误差去分析源数据与重建数据的差异。在重建任务（如图像重建或信号重建）中，传统的均方误差（MSE）通常被用来衡量模型生成的输出与目标之间的差异。然而，MSE 可能会有一个问题：它会对预测值的绝对大小非常敏感。因此，如果模型输出的预测结果在比例上正确（即，形状和结构与目标相似，但颜色或强度有所偏移），MSE 仍会产生较大的损失。这会导致模型在优化时，不仅关注形状和结构的准确性，还会尝试拟合输入的绝对尺度或强度。<strong>比例不变均方误差（Scale-Invariant MSE, SIMSE）</strong> 则不同。它专注于预测值与目标值之间的相对差异，忽略了绝对的强度差异。SIMSE 通过去除预测值和目标值之间的整体偏移来衡量误差，确保模型更关注结构和形状的还原，而不是绝对的颜色或强度。因此，SIMSE 在像素对之间的相对差异上更敏感，而不会因整体的亮度或比例不同而产生额外惩罚。</p>
$$
\begin{equation}
\mathcal{L}_{\text{difference}} = \left\| H_{c}^{s\top} H_{p}^{s} \right\|_{F}^{2} + \left\| H_{c}^{t\top} H_{p}^{t} \right\|_{F}^{2},
\end{equation}
$$
<p>$L_{difference}$用于鼓励<strong>共享编码器和专用编码器</strong>对输入的不同方面进行编码，从而分离数据的<strong>共享特征以及私有特征</strong>。使用正交约束，使得共享特征与私有特征的内积尽可能小，增大两者的独立性。</p>
$$
\begin{equation}
    \mathcal{L}_{\text{similarity }}^{\text{MMD}}= \frac{1}{(N^{s})^{2}}\sum_{i,j=0}^{N^{s}}\kappa(\mathbf{h}_{ci}^{s},\mathbf{h}_{cj}^{s})-\frac{2}{N^{s}N^{t}}\sum_{i,j=0}^{N^{s},N^{t}}\kappa(\mathbf{h}_{ci}^{s},\mathbf{h}_{cj}^{t})+\frac{1}{(N^{t})^{2}}\sum_{i,j=0}^{N^{t}}\kappa(\mathbf{h}_{ci}^{t},\mathbf{h}_{cj}^{t})
\end{equation}
$$

$$
\begin{equation}
    \mathcal{L}_{\text{similarity}}^{\text{DANN}}=\sum_{i=0}^{N_s+N_t}\left\{d_i\log\hat{d_i} + (1-d_i)\log(1-\hat{d_i})\right\}.
\end{equation}
$$

<p>使用MMD衡量源域和目标域之间共同特征的差异；使用反向的交叉熵损失函数，随着迭代的增加Loss增加，具体来说，训练一个专门的分类器，主要用于区分样本来自于源域还是目标域，不过训练的目的并不是正确分类，而是让分类器无法区分样本来自哪个域。</p>
</li>
</ul>
<h5 id="2-Domain-Invariant-and-Class-Discriminative-Feature-Learning-for-Visual-Domain-Adaptation-2018"><a href="#2-Domain-Invariant-and-Class-Discriminative-Feature-Learning-for-Visual-Domain-Adaptation-2018" class="headerlink" title="2.Domain Invariant and Class Discriminative Feature Learning for Visual Domain Adaptation(2018)"></a>2.Domain Invariant and Class Discriminative Feature Learning for Visual Domain Adaptation(2018)</h5><p><img src="https://gitee.com/sk4772/photo/raw/master/photo/20241203091614077.png" alt="image-20241126161927877"></p>
<ul>
<li><p><strong>提出背景：</strong>利用标记好的样本数据解决无标签样本，因为为样本打标签的过程是耗时昂给的。</p>
</li>
<li><p><strong>存在缺点：</strong>a）先前工作大多利用MMD等方法减少域之间的<strong>边缘分布</strong>，但不同域之间的<strong>条件分布</strong>也是存在差异的；b)  除此之外，仅减少域之间的差异是不足够的，因为减少差异的同时会降低数据的判别性，即不同类的样本变换到子空间后可能会相互靠近，影响分类器性能。</p>
</li>
<li><p><strong>方法创新：</strong></p>
<p>1.MMD减小域之间的边缘分布：</p>
$$
\begin{aligned}
\mathcal{L}_{MMD}^{(0)}& =\left\|\frac{1}{n_{s}}\sum_{i=1}^{n_{s}}z_{Si}-\frac{1}{n_{t}}\sum_{j=1}^{n_{t}}z_{Tj}\right\|^{2} \\
&=\left\|\frac{1}{n_{s}}\sum_{i=1}^{n_{s}}\mathbf{P}^{\top}\boldsymbol{x}_{Si}-\frac{1}{n_{t}}\sum_{j=1}^{n_{t}}\mathbf{P}^{\top}\boldsymbol{x}_{Tj}\right\|^{2} \\
&=\mathbf{Tr}\left(\mathbf{P}^\top\mathbf{X}\mathbf{W}_0\mathbf{X}^\top\mathbf{P}\right),
\end{aligned}
$$
<p>2.减少域之间的条件分布，因为目标域数据不存在标签数据，导致难以对齐条件分布，因此文章使用伪标签进行对齐，通过迭代优化伪标签：</p>
$$

$$
<p>3.分布建模</p>
<p>4.类内相似性建模</p>
<p>5.类间差异性建模</p>
<p>6.类内相似性和差异性统一</p>
</li>
</ul>
<h5 id="3-Robust-Transferable-Subspace-Learning-for-Cross-Corpus-Facial-Expression-Recognition-2020"><a href="#3-Robust-Transferable-Subspace-Learning-for-Cross-Corpus-Facial-Expression-Recognition-2020" class="headerlink" title="3.Robust Transferable Subspace Learning for Cross-Corpus Facial  Expression Recognition(2020)"></a>3.Robust Transferable Subspace Learning for Cross-Corpus Facial  Expression Recognition(2020)</h5><p><img src="https://gitee.com/sk4772/photo/raw/master/photo/20241203091621174.png" alt="image-20241126161959952"></p>
<ul>
<li><p><strong>提出背景：</strong>表情识别在严格条件获取的表情图像下可以很好的效果，但现实中表情图像往往来自于不同的设备或者环境，因此会存在不同域的数据，从而导致模型性能严重下降</p>
</li>
<li><p><strong>存在缺点：</strong>大多数方法仅通过<strong>MMD</strong>考虑数据之间的全局距离度量（global distance metric）,这样虽然可以拉近不同域之间的距离 ，但也会将不同类样本的距离拉近，降低模型的判别能力。</p>
</li>
<li><p><strong>方法创新：</strong></p>
<p>1.引入全局度量算法, 有效地减少<strong>特征分布差异</strong>并获得<strong>鲁棒</strong>不变特征表示</p>
<p>使用marginal MMD和conditional MMD，</p>
<p>2.考虑数据的<strong>判别</strong>知识以及数据本地的流形结构，提出了新的<strong>local discriminative distance metric</strong></p>
<p>​	首先在原先MMD的基础(<strong>全局结构</strong>)上添加条件MMD去考虑数据的<strong>局部结构</strong>即：</p>
$$
\min_{P} \operatorname{Tr}\left(P^T X (M_0 + M_C) X^T P\right) + \gamma \|P\|_F^2
$$
<p>其中$M_0$表述传统的MMD,$M_C$表示条件MMD，由下式表示：</p>
$$
\operatorname{Tr}(P^T X M_C X^T P) = \sum_{c=1}^{C} \left\| \frac{1}{N_S^c} \sum_{x_i \in \mathcal{D}_S^{(c)}} P^T x_i - \frac{1}{N_T^c} \sum_{x_j \in \mathcal{D}_T^{(c)}} P^T x_j \right\|^2
$$
<p>这个式子就是将同类样本取均值做MMD，其中关键之处是使用<strong>伪标签</strong>作为目标域的标签，因为原本的目标域是无标签的。</p>
<p>​	其次，使用<strong>标签拖拽</strong>增加判别能力，并构造源域内部图以及两域之间图即，他们的权重定义如下：</p>
$$
\begin{aligned}
{(W^S_w)}_{ij} = 
\begin{cases} 
1, & \text{if } i \neq j, y_{S_i} = y_{S_j} \\
0, & \text{otherwise}
\end{cases}
\\

{(W^T_w)}_{ij} = 
\begin{cases} 
1, & \text{if } i \neq j, \hat{y}_{T_i} = \hat{y}_{T_j} \\
0, & \text{otherwise}
\end{cases}
\end{aligned}
$$
<p>这里源域使用真实标签，目标域使用伪标签进行图的构造</p>
$$
\begin{aligned}
(W^{ST}_w)_{ij} = 
\begin{cases} 
1, & \text{if } x_j \in N^c_k(x_i) \text{ or } x_i \in N^c_k(x_j) \\
0, & \text{otherwise}
\end{cases}
\\
(W^{TS}_w)_{ji} = 
\begin{cases} 
1, & \text{if } x_i \in N^c_k(x_j) \text{ or } x_j \in N^c_k(x_i) \\
0, & \text{otherwise}
\end{cases}
\end{aligned}
$$
<p>这里通过判断最近邻设置图，构造最终的两个权重矩阵$W_w$和$W_b$</p>
$$
\begin{aligned}
W_w &= \begin{bmatrix}
W^S & W^{ST} \\
W^{TS} & W^T
\end{bmatrix}
\\
W_b &= \begin{bmatrix}
W^S & 0 \\
0 & W^T
\end{bmatrix}
\end{aligned}
$$
<p>通过此构造拉普拉斯矩阵$L_w &#x3D; D_w - W_w, \quad L_b &#x3D; D_b - W_b$，并以此构造流形正则项：</p>
$$
\min_{P} \operatorname{Tr}(P^T X (L_w - \lambda L_b) X^T P) = \min_{P} \operatorname{Tr}(P^T X L X^T P)
$$
<p>其实这两项就是<strong>域内图以及域间图</strong>的合并项。</p>
<p>最终目标函数为</p>
$$
\min_{P,V} \operatorname{Tr}(P^T X (\alpha M + \beta L) X^T P) + \gamma \|P\|_F^2 + \frac{1}{2} \|P^T X_S - (Y_S + B \odot V)\|_F^2\\

\text{s.t. } P^T P = I, V \geq 0
$$
</li>
<li></li>
</ul>
<h5 id="4-Balanced-Discriminative-Transfer-Feature-Learning-for-Visual-Domain-Adaptation（2021）"><a href="#4-Balanced-Discriminative-Transfer-Feature-Learning-for-Visual-Domain-Adaptation（2021）" class="headerlink" title="4.Balanced Discriminative Transfer Feature Learning for Visual Domain Adaptation（2021）"></a>4.Balanced Discriminative Transfer Feature Learning for Visual Domain Adaptation（2021）</h5><p>​	动机：迁移学习中使用特征匹配可以有效缓解域迁移过程中存在的问题但同等对待<strong>边缘分布和条件分布</strong>，忽视了两者之间的关系，除此之外域内的判别信息也被忽视。</p>
<p>方法：</p>
<ol>
<li>平衡边缘分布以及条件分布：通过MMD分别最小化边缘分布以及条件分布，至于两者之间的权重分配，当源域目标域之间的差距大时，更加注重边缘分布；而当两者很相似时，更加注重条件分布</li>
<li>判别信息：通过最小化类内相似性以及最大化类间差异性获得，注意目标域使用伪标签（pseudo label）</li>
<li>目标函数:</li>
</ol>
<h5 id="5-Discriminative-Fisher-Embedding-Dictionary-Transfer-Learning-for-Object-Recognition（2023）"><a href="#5-Discriminative-Fisher-Embedding-Dictionary-Transfer-Learning-for-Object-Recognition（2023）" class="headerlink" title="5.Discriminative Fisher Embedding Dictionary  Transfer Learning for Object Recognition（2023）"></a>5.Discriminative Fisher Embedding Dictionary  Transfer Learning for Object Recognition（2023）</h5><p>问题：目标域数据缺乏可用的标签</p>
<p>解决思想：将源域以及目标域数据投影到统一的子空间内；在此空间内，目标域数据可由源域数据组合表示，他们在此空间内可以很好地交错。两者分布大致相同，因此通过训练源域数据得到的模型可以很好地分类目标域数据.</p>
<table>
<thead>
<tr>
<th align="left">以往方法缺陷</th>
<th>补足</th>
</tr>
</thead>
<tbody><tr>
<td align="left">1.难以捕获数据内在结构</td>
<td></td>
</tr>
<tr>
<td align="left">2.没有考虑噪声</td>
<td></td>
</tr>
<tr>
<td align="left">3.忽略了将更改数据表示和分类器设计统一</td>
<td></td>
</tr>
</tbody></table>
<ul>
<li><input disabled="" type="checkbox"> 2.Dynamic Double Classifiers Approximation  for Cross-Domain Recognition（2022）</li>
</ul>
<h3 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h3><h5 id="1-Caltech256-and-Office"><a href="#1-Caltech256-and-Office" class="headerlink" title="1.Caltech256 and Office"></a>1.Caltech256 and Office</h5><p>Caltech256 是一个标准的对象识别数据集. 分  别从 Office 和 Caltech256 数据集中提取 1 410 幅 和 1 123 幅图像, 在 Office 中, A 子集含有 958 幅图  像, W 子集含有 295 幅图像, D 子集含有 157 幅图  像, 每幅图像被提取 SURF 特征并量化成 800 维的  向量, 因此两种不同的数据可以具有相同的特征空 间.</p>
<table>
<thead>
<tr>
<th>任务&#x2F;方法</th>
<th>BLS</th>
<th>DABLS</th>
<th>BLS+MMD</th>
<th>CD-CDBN</th>
<th>SS-BLS</th>
<th>TCA</th>
<th>CDELM</th>
</tr>
</thead>
<tbody><tr>
<td>A→C</td>
<td>20.82</td>
<td>44.29</td>
<td><strong>44.97</strong></td>
<td>35.56</td>
<td>42.16</td>
<td>40.78</td>
<td>31.67</td>
</tr>
<tr>
<td>A→D</td>
<td>17.83</td>
<td>42.06</td>
<td><strong>43.95</strong></td>
<td>33.79</td>
<td>39.40</td>
<td>31.85</td>
<td>32.48</td>
</tr>
<tr>
<td>A→W</td>
<td>19.61</td>
<td>42.09</td>
<td>37.63</td>
<td>27.46</td>
<td>40.61</td>
<td>37.63</td>
<td>31.47</td>
</tr>
<tr>
<td>C→A</td>
<td>29.16</td>
<td>51.68</td>
<td><strong>52.92</strong></td>
<td>38.78</td>
<td>49.67</td>
<td>44.89</td>
<td>44.99</td>
</tr>
<tr>
<td>C→D</td>
<td>24.84</td>
<td>45.85</td>
<td><strong>49.04</strong></td>
<td>36.94</td>
<td>44.20</td>
<td>45.84</td>
<td>35.37</td>
</tr>
<tr>
<td>C→W</td>
<td>20.46</td>
<td>47.79</td>
<td>44.07</td>
<td>35.54</td>
<td>45.74</td>
<td>36.61</td>
<td>38.92</td>
</tr>
<tr>
<td>D→A</td>
<td>32.42</td>
<td>36.73</td>
<td><strong>36.74</strong></td>
<td>28.34</td>
<td>35.57</td>
<td>31.52</td>
<td>30.61</td>
</tr>
<tr>
<td>D→C</td>
<td>30.03</td>
<td>32.47</td>
<td>32.24</td>
<td>26.79</td>
<td>30.19</td>
<td>32.50</td>
<td>28.96</td>
</tr>
<tr>
<td>D→W</td>
<td>79.98</td>
<td>80.06</td>
<td>78.31</td>
<td>50.78</td>
<td>79.11</td>
<td>87.12</td>
<td>76.95</td>
</tr>
<tr>
<td>W→A</td>
<td>34.61</td>
<td>40.01</td>
<td>37.06</td>
<td>30.89</td>
<td>37.51</td>
<td>30.69</td>
<td>35.55</td>
</tr>
<tr>
<td>W→C</td>
<td>31.73</td>
<td>36.50</td>
<td>31.52</td>
<td>27.26</td>
<td>35.29</td>
<td>27.16</td>
<td>32.03</td>
</tr>
<tr>
<td>W→D</td>
<td>80.81</td>
<td>82.73</td>
<td><strong>84.08</strong></td>
<td>50.42</td>
<td>80.89</td>
<td>90.45</td>
<td>78.99</td>
</tr>
<tr>
<td>平均值</td>
<td>35.19</td>
<td>48.52</td>
<td>47.71</td>
<td>35.21</td>
<td>46.69</td>
<td>45.38</td>
<td>41.50</td>
</tr>
</tbody></table>
<table>
<thead>
<tr>
<th>任务&#x2F;方法</th>
<th>DABLS</th>
<th>BLS+MMD(复现)</th>
</tr>
</thead>
<tbody><tr>
<td>COIL20_1-&gt;COIL_2</td>
<td>88.12</td>
<td><strong>89.86</strong></td>
</tr>
<tr>
<td>COIL20_2-&gt;COIL_1</td>
<td>84.72</td>
<td><strong>88.89</strong></td>
</tr>
</tbody></table>
<table>
<thead>
<tr>
<th>任务&#x2F;方法</th>
<th>DABLS</th>
<th>BLS+MMD(复现)</th>
</tr>
</thead>
<tbody><tr>
<td>ImageNet-&gt;VOC2007</td>
<td>67.83</td>
<td><strong>69.05</strong></td>
</tr>
<tr>
<td>VOC2007-&gt;ImageNet</td>
<td>77.87</td>
<td><strong>79.68</strong></td>
</tr>
</tbody></table>
<table>
<thead>
<tr>
<th>任务&#x2F;方法</th>
<th>DABLS</th>
<th>BLS+MMD(复现)</th>
</tr>
</thead>
<tbody><tr>
<td>MNIST-&gt;USPS</td>
<td>68.54</td>
<td>59.33</td>
</tr>
<tr>
<td>USPS-&gt;MNIST</td>
<td>50.13</td>
<td>46.75</td>
</tr>
</tbody></table>
]]></content>
      <categories>
        <category>Transfer Learning</category>
      </categories>
      <tags>
        <tag>调研</tag>
        <tag>写作</tag>
      </tags>
  </entry>
</search>
